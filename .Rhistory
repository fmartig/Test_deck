qplot(x,CompressiveStrength,data=training,color=cutCement)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength),colour=cutCement)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutCement))
cutCement<-cut2(training$Cement,g=2)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutCement))
cutFlyAsh<-cut2(training$FlyAsh,g=3)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutFlyAsh))
cutAge<-cut2(training$Age,g=4)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutFlyAsh))
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutAge))
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutCement))
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutFlyAsh))
cutFlyAsh<-cut2(training$FlyAsh,g=4)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutFlyAsh))
cutFlyAsh<-cut2(training$FlyAsh,g=4)
levels(cutFlyAsh)
cutFlyAsh<-cut2(training$FlyAsh,g=3)
levels(cutFlyAsh)
cutFlyAsh<-cut2(training$FlyAsh,g=2)
levels(cutFlyAsh)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutFlyAsh))
names(training)
cutBFS<-cut2(training$BlastFurnaceSlag,g=4)
cutWater<-cut2(training$Water,g=4)
cutSuper<-cut2(training$Superplasticizer,g=4)
cutCA<-cut2(training$CoarseAggregate,g=4)
cutFA<-cut2(training$FineAggregate,g=4)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutBFS))
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutWater))
cutWater<-cut2(training$Water,g=3)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutWater))
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutSuper))
cutSuper<-cut2(training$Superplasticizer,g=2)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutSuper))
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutCA))
cutCA<-cut2(training$CoarseAggregate,g=3)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutCA))
cutFA<-cut2(training$FineAggregate,g=3)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutFA))
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutFlyAsh))
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutAge))
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutFlyAsh))
qplot(x,CompressiveStrength,data=training)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutAge))
cutAge<-cut2(training$Age,g=3)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutAge))
cutAge<-cut2(training$Age,g=4)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutAge))
cutFlyAsh<-cut2(training$FlyAsh,g=4)
ggplot(training)+geom_point(aes(x=x,y=CompressiveStrength,colour=cutFlyAsh))
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(SuperPlasticizer,data=training)
qplot(Superplasticizer,data=training)
ln<-log(training$Superplasticizer+1)
qplot(ln)
qplot(Superplasticizer,data=training)
qplot(ln)
qplot(Superplasticizer,data=training)
library(kernlab)
install.packages("kernlab")
library(kernlab)
data(spam)
inTrain<-createDataPartition(y=spam$type,p=0.75,list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
data(AlzheimerDisease)
set.seed(3433)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
subt<-training$IL
subt<-names(training)$IL
subt<-names(training)[["IL",exact=FALSE]]
subt<-training[,58:69]
names(subt)
?grepl
il<-grepl("IL*",names(training))
sub<-training[,il]
View(sub)
il<-grepl("^IL*",names(training))
sub<-training[,il]
View(sub)
il<-grepl("^IL",names(training))
sub<-training[,il]
View(sub)
sub<-training[,il]
View(sub)
names(sub)
prComp<-prcomp(sub)
prComp$rotation
n<-nrow(sub)
n
View(sub)
totvar<-apply(sub,2,var)
totvar
sum(totvar)
vardata<-sum(totvar)
test<-sum(prComp$rotation[,1]*sub)
pc1<-1/n*sum(sum(prComp$rotation[,1]*sub)^2)
pc1/vardata
var(sub)
test<-diag(var(sub))
test
var(prComp$rotation[,1])
var(prComp$rotation[,1])/sum(test)
var(prComp$rotation[,2])
sum(var(prComp$rotation[,1],var(prComp$rotation[,2]),var(prComp$rotation[,3]),var(prComp$rotation[,4]),var(prComp$rotation[,5]),var(prComp$rotation[,6],var(prComp$rotation[,7]),var(prComp$rotation[,8]),var(prComp$rotation[,9]),var(prComp$rotation[,10]),var(prComp$rotation[,11]),var(prComp$rotation[,12]))
)
)
sum(var(prComp$rotation[,1],var(prComp$rotation[,2]))
)
?sum
varpc<-apply(prComp$rotation,2,var)
varpc
sum(varpc)
totvar<-sum(apply(sub,2,var))
totvar
var(prComp$rotation[,1])
?cov
cov(prComp$rotation)
diag(cov(prComp$rotation))
diag(cov(sub))
covMat<-cov(prComp$rotation)
eigen(covMat,symmetric=TRUE)
eigenval<-eigen(covMat,symmetric=TRUE)$values
eigenval
sum(eigenval)
prComp$rotation
test<-sum(sum(sub)^2)
subsqu<-sub^2
subsqu<-as.matrix(sub^2)
subsqu
step1<-apply(subsqu,1,sum)
step2<-sum(step1)
step2/n
prComp<-prcomp(sub,center=TRUE,scale.=TRUE)
prComp$rotation
varpc<-apply(prComp$rotation,2,var)  #variance of each principal component NOT RIGHT ?
varpc
sum(varpc)
prComp<-prcomp(sub,center=TRUE,scale.=TRUE)
plot(prComp,type="l")
summary(prComp)
log_sub<-log(sub)
log_sub<-log(sub+1)
?preProcess
trans<-preProcess(sub,method=c("BoxCox","center","scale","pca"))
trans<-preProcess(sub,method=c("BoxCox","center","scale","pca"),thresh=0.80)
PC<-predict(trans,sub)
head(PC,3)
transfull<-preProcess(sub,method=c("BoxCox","center","scale","pca"))
PCfull<-predict(transfull,sub)
head(PCfull,3)
prComp<-prcomp(sub,center=TRUE,scale.=TRUE)
summary(prComp)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
il<-grepl("^IL",names(training))
View(testing)
sub<-training[,il]
trainsub<-cbind(diagnosis,sub)
sub<-training[,il]
trainsub<-cbind(training$diagnosis,sub)
View(trainsub)
View(training)
mod1<-train(diagnosis~.,data=trainsub,method="glm")
mod1<-train(trainsub$diagnosis~.,data=trainsub,method="glm")
head(trainsub)
trainsub$diagnosis<-as.factor(trainsub$diagnosis)
trainsub<-cbind(training[,1],sub)
head(trainsub)
trainsub$diagnosis<-trainsub$training[,1]
names(trainsub)<-c("diagnosis","11","13","16","17E","1alpha","3","4","5","6","Receptor","7","8")
head(trainsub)
mod1<-train(diagnosis~.,data=trainsub,method="glm")
summary(mod1)
mod1
mod1<-train(diagnosis~.,data=trainsub,preProcess=c("center","scale"),method="glm")
mod1
preproc<-preProcess(trainsub[,-1],method="pca",pcaComp=7)
trainPC<-predict(preproc,trainsub[,-1])
mod2<-train(trainsub$diagnosis~.,method="glm",data=trainPC)
il<-grepl("^IL",names(testing))
sub2<-testing[,il]
testsub<-cbind(testing[,1],sub2)
names(testsub)<-c("diagnosis","11","13","16","17E","1alpha","3","4","5","6","Receptor","7","8")
testPC2<-predict(preproc,testsub[,-1])
confusionMatrix(testsub$diagnosis~.,predict(Mod2,testPC2))
confusionMatrix(testsub$diagnosis,predict(Mod2,testPC2))
confusionMatrix(testsub$diagnosis,predict(mod2,testPC2))
confusionMatrix(testsub$diagnosis,predict(mod1,testsub))
il<-grepl("^IL",names(training))
sub<-training[,il]
trans<-preProcess(sub,method=c("BoxCox","center","scale","pca"),thresh=0.80)
trans<-preProcess(sub,method=c("BoxCox","center","scale","pca"),thresh=0.90)
PC<-predict(trans,sub)
head(PC,3)
fileUrl="https://d3c33hcgiwev3.cloudfront.net/_4128d258838072915c2c1e039b4aac4d_019predictingWithTrees.pdf?Expires=1452816000&Signature=bgBULwKGWscZtBKyVIlHSiwdQoYAZOHgFC5rV-mqYC0130naPvDeaaKDA4uihhdPbXKGojmvIKXy1Hbc4Wa6gWVYn~Oi-U2mecUMLDmUNyvDAjQ1mqn1o6CdNH~-PLbRdHjE~hXR3Z1gMsYV6TCpOtuGz8S5rHsnK1nANlFEHqg_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A"
download.file(fileUrl, destfile="~/Documents/Data_science/08_MachLearning/Lectures/019predictingWithTrees.pdf", method="curl")
fileUrl="https://d3c33hcgiwev3.cloudfront.net/_4af56cc83ecb526844445a787a746190_020bagging.pdf?Expires=1452816000&Signature=axPHr5cLgIYEb3a-BoU9f5JLv-ESm8zD7s2dflR8FXS~Ut1ygVqB5vOQhyTwBaLbFj2c6~u17Fb7MsOtEn-4120mh6CVfQrvGTD6oh4aw7iU6JAtaqHzWxNRe5EvPVH5C50jleSPw5HcB4s1KK3wdEiVdzsFcLukAGnBzlaaItU_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A"
download.file(fileUrl, destfile="~/Documents/Data_science/08_MachLearning/Lectures/020bagging.pdf", method="curl")
fileUrl="https://d3c33hcgiwev3.cloudfront.net/_22b8678c43954c48daa5bb151a6a9a0f_021randomForests.pdf?Expires=1452816000&Signature=NCTZFB07AdIIjfwViL0y1O39~LE4kyNTjNMquzQBq-GZ8Jyvsv7u4DAja3~0SW8Ut17GQgBtPwcovVmz1MPkKp-3WzXjmB4cinI46nC0ZIWOfmrduXF8UakzGjQyZKFBEfb2qi27jkRpkWZtAmuy9dfsBd0FQiVm87q5PBKjuBg_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A"
download.file(fileUrl, destfile="~/Documents/Data_science/08_MachLearning/Lectures/021randomForests.pdf", method="curl")
fileUrl="https://d3c33hcgiwev3.cloudfront.net/_15e2455eecc909c8a65d99aa3b50d53b_022boosting.pdf?Expires=1452816000&Signature=buD5TAfaVGQNu4SkLyyOtMQMIyuBr0q2Wm42ZN9qbhxUn9iEy~BJSDRdDK55gaxTa2Znr8kH0eBzI2nf~ZGLh~hG2A3fI-k~hiJhT-r1K~r2XSzJxj2e0mjiXESFHu0-ZExSKOq3mDawR9X2LQlqmmzz8l8M-T5b76NEhCK2CjU_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A"
download.file(fileUrl, destfile="~/Documents/Data_science/08_MachLearning/Lectures/022boosting.pdf", method="curl")
fileUrl="https://d3c33hcgiwev3.cloudfront.net/_82cafd5da7820222defb1f171729cf45_023modelBasedPrediction.pdf?Expires=1452816000&Signature=Tjbd4M-fkE57Wv6FjXITki61iYuvGk2dlW5plgpC4lnkWZ1xMmFwC-Ti4Ubo4V8gtly2jwo1BaRAqKm6Jtdzfo-kyFHeHdEMlxOtqklUOIaxVEDdY8jJYks6dX3IihLuQsKhBfSTKGGzYED~Cebu5GyGfCQTXAo88HSak5nAEIQ_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A"
download.file(fileUrl, destfile="~/Documents/Data_science/08_MachLearning/Lectures/023modelBasedPrediction.pdf", method="curl")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
names(segmentationOriginal)
inTrain<-createDataPartition(y=segmentationOriginal$Case,p=0.7,list=FALSE)
training<-segmentationOriginal[inTrain,]
testing<-segmentationOriginal[-inTrain,]
dim(training)
dim(testing)
set.seed(125)
unique(segmentationOriginal$Case)
View(segmentationOriginal)
unique(segmentationOriginal$Class)
test1<-subset(testing,TotalIntench2 == 23000 & FiberWidthCh1==10 & PerimStatusCh1=2)
test1<-testing[testing$TotalIntench2==23000 & testing$FiberWidthCh1==10 & testing$PerimStatusCh1=2,]
test1<-testing[testing$TotalIntench2==23000 & testing$FiberWidthCh1==10 & testing$PerimStatusCh1==2,]
test1<-testing[testing$TotalIntench2==23000,]
View(testing)
test1<-testing[testing$PerimStatusCh1==2,]
View(test1)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
View(segmentationOriginal)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
test1<-testing[testing$TotalIntench2==23000,]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
library(ElemStatLearn)
install.pckages("ElemStatLearn")
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y<-as.factor(vowel.train$y)
View(vowel.train)
vowel.test<-as.data.frame(vowel.test)
vowel.test$y<-as.factor(vowel.test$y)
mod3<-train(Area~.,method="rpart",data=olive)
newdata = as.data.frame(t(colMeans(olive)))
mod3<-tree(Area~.,data=olive)
library(tree)
install.packages("tree")
mod3<-tree(Area~.,data=olive)
library(tree)
mod3<-tree(Area~.,data=olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(mod3,newdata)
print(modFit$finalModel)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
modFit<-train(Class~.,method="rpart",data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE)
plot(modFit$finalModel, uniform=TRUE,main="Classification tree")
text(modFit$finalModel,use.n=TRUE,all=TRUE,cex=0.8)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
print(modFit$finalModel)
? varImp
mod5<-train(y~.,data=vowel.train,method="rf",prox=TRUE)
mod5<-train(y~.,data=vowel.train,method="rf",prox=TRUE)
imp<-varImp(mod5)
imp
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel<-rbind(vowel.train,vowel.test)
View(vowel)
vowel$y<-as.factor(vowel$y)
set.seed(33833)
mod5<-train(y~.,data=vowel,method="rf",prox=TRUE)
imp<-varImp(mod5)
imp
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
mod5<-train(y~.,data=vowel.train,method="rf",prox=TRUE)
imp<-varImp(mod5)
imp
set.seed(33833)
mod6<-train(y~.,data=vowel.test,method="rf",prox=TRUE)
imp<-varImp(mod6)
imp
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
View(trainSA)
set.seed(13234)
mod4<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd,predict(mod4))
missClass(testSA$chd,predict(mod4,newdata=testSA))
glm4<-glm(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,family="binomial")
missClass(trainSA$chd,predict(glm4))
missClass(testSA$chd,predict(glm4,newdata=testSA))
missClass(trainSA$chd,mod4$fitted)
missClass(trainSA$chd,glm4$fitted)
fileUrl="https://d3c33hcgiwev3.cloudfront.net/_64272eb0e91bb682508ad10123a7b767_024regularizedRegression.pdf?Expires=1453161600&Signature=Oke4yEEIccNppSl6WNr40Fv37p4uupz2le~np3U517ig3Gn25oFJCoxr2QJs9XnaqZ5Iri~xQUwKwsrwI0deJle09YPLc2cyf9cOPrn4hV12sYyX~1QRWb9reAbpbcKWETykOLGWICOl8gDvBriD5ycLZhipy6Vat3zOUq8BWtY_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A"
download.file(fileUrl, destfile="~/Documents/Data_science/08_MachLearning/Lectures/024regularizedRegression.pdf", method="curl")
fileUrl="https://d3c33hcgiwev3.cloudfront.net/_7dc5d903db1fd6ed5c11cc4cc386a072_025combiningPredictors.pdf?Expires=1453161600&Signature=Ss627cMvSlzMl77SXYhRi35i25YIiETlg7RVfFZOMtvBPYweCsMlEbSfZw4OEXNtUQ6tPnAJXedlUY3Cy1XZohNAu08EDhR1PpXynltul~LSGG8Cbs3IlUpegWvc8uGW9SI0c7n7d1TlIjsjy4KbABQvqr6beEyD1YtJqTIGEBY_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A"
download.file(fileUrl, destfile="~/Documents/Data_science/08_MachLearning/Lectures/025combiningPredictors.pdf", method="curl")
fileUrl="https://d3c33hcgiwev3.cloudfront.net/_b0b09d7bf4a299f0221d5af9c2594b15_027forecasting.pdf?Expires=1453161600&Signature=PNJ-T6jqSYuYIxf9D-6rLktJ~FmcFpJhEQDACIvZqD6qK4ynOwT0RFmVB9dV2Kqq7M6YB~gwZ8e4dvqIPVtya4LemDm1OqY40gSdjmNncujkE~hIChp1pVH3asn6EwHTsXYFBVl~h-3MsDQiZnjPeB0O16ayMt-jSB9CC7DPCpE_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A"
download.file(fileUrl, destfile="~/Documents/Data_science/08_MachLearning/Lectures/027forecasting.pdf.pdf", method="curl")
fileUrl="https://d3c33hcgiwev3.cloudfront.net/_1cbfe1d8381500954229b22477bf09c4_026unsupervisedPrediction.pdf?Expires=1453161600&Signature=FI31aonk2sFar89rabIXkJuiWxzxf6PEWzq33sC3a~Oe52SVvHhg-raG726C50E0OaZYc7yRfiu7UaoxImpOk5Tt4bL-Y4CcCR8LQBaMUvodIGTGR7DrF-cOVyxhphlg5CL9mj2bmyJuaKkgBinFwWrkPXTpwinfLWMh-Jx~GBk_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A"
download.file(fileUrl, destfile="~/Documents/Data_science/08_MachLearning/Lectures/026unsupervisedPrediction.pdf", method="curl")
library(devtools)
install_github('rCharts', 'ramnathv')
require(rCharts)
haireye = as.data.frame(HairEyeColor)## Generate the plotn1 = nPlot(Freq ~ Hair, group = 'Eye', type = 'multiBarChart',           data = subset(haireye, Sex == 'Male'))## Display the plotn1
haireye = as.data.frame(HairEyeColor)
n1 = nPlot(Freq ~ Hair, group = 'Eye', type = 'multiBarChart',           data = subset(haireye, Sex == 'Male'))
n1 = nPlot(Freq ~ Hair, group = 'Eye', type = 'multiBarChart', data = subset(haireye, Sex == 'Male'))
n1
data(economics, package = "ggplot2")
econ = transform(economics, date = as.character(date))
m1 = mPlot(x = "date", y = c("psavert", "uempmed"), type = "Line", data = econ)
m1$set(pointSize = 0, lineWidth = 1)
m1
install.packages("googleVis")
library(googleVis)
M = gvisMotionChart(Fruits, "Fruit", "Year", options = list(width = 600, height = 400))
plot(M)
stateDF = data.frame(State = state.name, state.x77)
gchart = gvisGeoChart(data = stateDF,                      plot(gchart)
gchart = gvisGeoChart(data = stateDF,plot(gchart))
gchart = gvisGeoChart(data = stateDF)
plot(gchart)
gchart = gvisGeoChart(data = stateDF,                      plot(gchart)                      locationvar = "State",                      colorvar = "Population",                      options = list(region="US",                                     displayMode="regions",                                     resolution="provinces",                                     width=600, height=400))
gchart = gvisGeoChart(data = stateDF,                      locationvar = "State",                      colorvar = "Population",                      options = list(region="US",                                     displayMode="regions",                                     resolution="provinces",                                     width=600, height=400))
gchart = gvisGeoChart(data = stateDF,locationvar = "State",colorvar = "Population",options = list(region="US",displayMode="regions",resolution="provinces",width=600, height=400))
plot(gchart)
head(stateDF)
install.package("leaflet")
install.packages("leaflet")
install.packages("leafletR")
library(leafletR)
m = leaflet() %>%    addTiles() %>%    addMarkers(lat=39.298113, lng=-76.590248, popup="Where Brian works")
m = leaflet() %>%        addTiles() %>%        addMarkers(lat=39.298113, lng=-76.590248, popup="Where Brian works")
install.packages("leaflet")
m = leaflet() %>%        addTiles() %>%        addMarkers(lat=39.298113, lng=-76.590248, popup="Where Brian works")
library(leaflet)
require(leaflet)
library(leaflet)
install.packages("leaflet")
M = gvisMotionChart(Fruits, "Fruit", "Year", options = list(width = 600, height = 400))
print(M,"chart")
library(rCharts)
library(datasets)
?dTable
data(airquality)
dTable(airquality,sPaginationType="full_numbers")
fileUrl="https://github.com/bcaffo/courses/blob/master/09_DevelopingDataProducts/lectures/RPackages.pdf?raw=true"
download.file(fileUrl, destfile="~/Documents/Data_science/09_DataProducts/Lectures/RPackages.pdf", method="curl")
fileUrl="https://github.com/bcaffo/courses/blob/master/09_DevelopingDataProducts/lectures/RPackages.pdf"
download.file(fileUrl, destfile="~/Documents/Data_science/09_DataProducts/Lectures/RPackages.pdf", method="curl")
mean
predict
dgamma
colSums
lm
setwd("~/Documents/Data_science/09_DataProducts/Exercises/air_pollutionEU")
emissions<-read.table("env_air_emis.tsv",header=TRUE, sep='\t', na.strings=c("0 n",": z",": "))
library(tidyr)
emissions<-separate(emissions,unit.airpol.airsect.geo.time,c("unit","airpol","sect","geo"), sep=",")
emissions$geo<-gsub("UK","GB",emissions$geo)
emissions$geo[emissions$geo=="EL"]<-"GR"
library(dplyr)
emissions<-mutate(emissions,airpol=factor(airpol),sect=factor(sect),geo=factor(geo))
SOX_FR<-filter(emissions,geo=="FR",airpol=="SOX",sect=="SE1_EPD"|sect=="SE1_EUI"|sect=="SE1_RD"|sect=="SE2_IP")
names(SOX_FR)[5:28]<-c(2013:1990)
SOX_FR_L<-melt(SOX_FR,id=c("unit","airpol","sect", "geo"))
SOX_FR_L<-SOX_FR_L%>%
dplyr::rename(time=variable,emission=value)%>%
mutate(time=as.Date(time,"%Y"),year=year(time),year=as.numeric(year))%>%
arrange(year)
library(reshape)
SOX_FR<-filter(emissions,geo=="FR",airpol=="SOX",sect=="SE1_EPD"|sect=="SE1_EUI"|sect=="SE1_RD"|sect=="SE2_IP")
names(SOX_FR)[5:28]<-c(2013:1990)
SOX_FR_L<-melt(SOX_FR,id=c("unit","airpol","sect", "geo"))
SOX_FR_L<-SOX_FR_L%>%
dplyr::rename(time=variable,emission=value)%>%
mutate(time=as.Date(time,"%Y"),year=year(time),year=as.numeric(year))%>%
arrange(year)
library(lubridate)
SOX_FR<-filter(emissions,geo=="FR",airpol=="SOX",sect=="SE1_EPD"|sect=="SE1_EUI"|sect=="SE1_RD"|sect=="SE2_IP")
names(SOX_FR)[5:28]<-c(2013:1990)
SOX_FR_L<-melt(SOX_FR,id=c("unit","airpol","sect", "geo"))
SOX_FR_L<-SOX_FR_L%>%
dplyr::rename(time=variable,emission=value)%>%
mutate(time=as.Date(time,"%Y"),year=year(time),year=as.numeric(year))%>%
arrange(year)
library(googleVis)
M2<-gvisMotionChart(SOX_FR_L, idvar="sect", timevar="time", x="year",y="emission",options = list(width = 700, height = 500))
plot(M2)
write.csv(SOX_FR_L,"sox_fr.csv")
setwd("~/Documents/Data_science/09_DataProducts/Exercises/Test_deck")
library(slidify)
slidify("index.Rmd")
sox_fr<-read.csv("~/Documents/Data_science/09_DataProducts/Exercises/air_pollutionEU/sox_fr.csv")
str(sox_fr)
sox_fr<-read.csv("~/Documents/Data_science/09_DataProducts/Exercises/air_pollutionEU/sox_fr.csv", stringsAsFactors=FALSE)
str(sox_fr)
sox_fr$time<-as.Date(sox_fr$time)
str(sox_fr)
slidify("index.Rmd")
sox_fr<-read.csv("~/Documents/Data_science/09_DataProducts/Exercises/air_pollutionEU/sox_fr.csv")
sox_fr$time<-as.Date(sox_fr$time)
str(sox_fr)
sox_fr<-read.csv("~/Documents/Data_science/09_DataProducts/Exercises/air_pollutionEU/sox_fr.csv", stringsAsFactors=FALSE)
sox_fr$time<-as.Date(sox_fr$time)
str(sox_fr)
slidify("index.Rmd")
M1<-gvisMotionChart(sox_fr[,3:8],idvar="sect", timevar="time", x="year",y="emission",options = list(width = 700, height = 500))
plot(M1)
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
slidify("index.Rmd")
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
code<-unique(emissions$sect)
sectors<-c("Commercial, institutional and households","Energy production and distribution","Energy use in industry","Non-road transport","Road transport","Industrial processes and product use","Agriculture","Waste","Other","National total for the entire territory (based on fuel sold)")
sect_table<-data.frame(Code=code,Sector=sectors)
kable(sect_table)
xtable(sect_table)
library(xtable)
xtable(sect_table)
xtable(sect_table,type="html")
xtable(sect_table,type="html")
sectors.table<-xtable(sect_table)
print(sectors.table,type="html", include.rownames=FALSE)
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
rundeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
runDeck()
